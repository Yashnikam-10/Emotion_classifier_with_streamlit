{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense as dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, Bidirectional, Conv1D, GRU\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Emotion                                               Text\n",
       "0  neutral                                              Why ?\n",
       "1      joy    Sage Act upgrade on my to do list for tommorow.\n",
       "2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...\n",
       "3      joy   Such an eye ! The true hazel eye-and so brill...\n",
       "4      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/raw_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'joy', 'sadness', 'fear', 'surprise', 'anger', 'shame',\n",
       "       'disgust'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [preprocess_text(sent) for sent in df['Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CleanText'] = df['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CleanText'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Emotion']\n",
    "# Binarize labels with SKLearn label binarizer\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize sentencs to numbers with max number 10000\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "# Pad sequences to max length with post padding.\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding file\n",
    "embeddings_dictionary = dict()\n",
    "with open(\"data/glove.6B.100d/glove.6B.100d.txt\", encoding=\"utf8\") as glove_file:\n",
    "    for line in glove_file:\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "        embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False),\n",
    "    Bidirectional(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)),\n",
    "    Bidirectional(LSTM(54, dropout=0.3, recurrent_dropout=0.3, return_sequences=True)),\n",
    "    Bidirectional(LSTM(60, dropout=0.3, recurrent_dropout=0.3)),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(8, activation=\"softmax\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 100, 100)          3184200   \n",
      "                                                                 \n",
      " bidirectional_18 (Bidirecti  (None, 100, 100)         60400     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_19 (Bidirecti  (None, 100, 108)         66960     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_20 (Bidirecti  (None, 120)              81120     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                7744      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,400,944\n",
      "Trainable params: 216,744\n",
      "Non-trainable params: 3,184,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "174/174 [==============================] - 550s 3s/step - loss: 1.5864 - accuracy: 0.3865 - val_loss: 1.4464 - val_accuracy: 0.4455\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 538s 3s/step - loss: 1.4066 - accuracy: 0.4689 - val_loss: 1.3376 - val_accuracy: 0.5073\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 531s 3s/step - loss: 1.2987 - accuracy: 0.5204 - val_loss: 1.2875 - val_accuracy: 0.5227\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 536s 3s/step - loss: 1.2354 - accuracy: 0.5491 - val_loss: 1.2302 - val_accuracy: 0.5520\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 537s 3s/step - loss: 1.1912 - accuracy: 0.5652 - val_loss: 1.1850 - val_accuracy: 0.5649\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 546s 3s/step - loss: 1.1509 - accuracy: 0.5829 - val_loss: 1.1818 - val_accuracy: 0.5761\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 544s 3s/step - loss: 1.1210 - accuracy: 0.5905 - val_loss: 1.1558 - val_accuracy: 0.5746\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 541s 3s/step - loss: 1.0875 - accuracy: 0.6041 - val_loss: 1.1447 - val_accuracy: 0.5915\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 541s 3s/step - loss: 1.0679 - accuracy: 0.6122 - val_loss: 1.1096 - val_accuracy: 0.5906\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 549s 3s/step - loss: 1.0338 - accuracy: 0.6269 - val_loss: 1.1119 - val_accuracy: 0.5915\n"
     ]
    }
   ],
   "source": [
    "# Train/fit model on dataset\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/final_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save model in tf-format\n",
    "model.save(\"data/final_model\")\n",
    "np.save(\"data/class_names.npy\", encoder.classes_) # classes can be saved in json, text or numpy format.\n",
    "\n",
    "# Save tokenizer as pickle\n",
    "with open('data/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Load class names\n",
    "classNames = np.load(\"data/class_names.npy\")\n",
    "\n",
    "# Load tokenizer pickle file\n",
    "with open('data/tokenizer.pickle', 'rb') as handle:\n",
    "        Tokenizer = pickle.load(handle)\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model(\"data/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I am very happy.....\"\n",
    "sentence_processed = Tokenizer.texts_to_sequences([sentence])\n",
    "sentence_processed = np.array(sentence_processed)\n",
    "sentence_padded = tf.keras.preprocessing.sequence.pad_sequences(sentence_processed, padding='post', maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger' 'disgust' 'fear' 'joy' 'neutral' 'sadness' 'shame' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "print(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 410ms/step\n",
      "Emotion class for given text is: joy\n",
      "['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'shame', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(sentence_padded)\n",
    "# Show prediction\n",
    "print(\"Emotion class for given text is: {}\".format(classNames[np.argmax(result)]))\n",
    "print([name for name in classNames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"How can you do such a filthy act!!!!\"\n",
    "sentence_processed = Tokenizer.texts_to_sequences([sentence])\n",
    "sentence_processed = np.array(sentence_processed)\n",
    "sentence_padded = tf.keras.preprocessing.sequence.pad_sequences(sentence_processed, padding='post', maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>neutral</th>\n",
       "      <th>sadness</th>\n",
       "      <th>shame</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.886155</td>\n",
       "      <td>0.00685</td>\n",
       "      <td>0.042938</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.050767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger   disgust    fear       joy  neutral   sadness     shame  surprise\n",
       "0  0.003883  0.000707  0.0087  0.886155  0.00685  0.042938  0.000001  0.050767"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame(result, columns=[name for name in classNames])\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = output_df.T.plot.bar(y=0, rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>0.312799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>0.015754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0.106170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>0.091074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.423814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>0.029259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shame</th>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>0.020961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "anger     0.312799\n",
       "disgust   0.015754\n",
       "fear      0.106170\n",
       "joy       0.091074\n",
       "neutral   0.423814\n",
       "sadness   0.029259\n",
       "shame     0.000169\n",
       "surprise  0.020961"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-62-0ff673a2e044>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-62-0ff673a2e044>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    output_df.iloc[]\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
